{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOag/IL3QFC0xRKxGzqHdyb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mcavol/AI-vs-Human-Text-Detector/blob/main/AI_vs_Human_Detector_with_Roberta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q --upgrade \"transformers>=4.40\" accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKfIk-CgzY9g",
        "outputId": "7150cd6f-8421-42f4-82de-0216882a1f6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m98.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch, textwrap\n",
        "\n",
        "MODEL_NAME = \"openai-community/roberta-base-openai-detector\"  # swap anytime\n",
        "\n",
        "device_id = 0 if torch.cuda.is_available() else -1\n",
        "clf = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=AutoModelForSequenceClassification.from_pretrained(MODEL_NAME),\n",
        "    tokenizer=AutoTokenizer.from_pretrained(MODEL_NAME),\n",
        "    return_all_scores=True,\n",
        "    device=device_id,\n",
        ")\n",
        "\n",
        "LABEL = {\"Real\": \"HUMAN\", \"Fake\": \"AI\"}\n",
        "\n",
        "def classify(text: str) -> tuple[str, float]:\n",
        "    scores = clf(text, truncation=True, max_length=512)[0]\n",
        "    best = max(scores, key=lambda s: s[\"score\"])\n",
        "    return LABEL[best[\"label\"]], best[\"score\"]\n",
        "\n",
        "print(\"Paste text (empty line = quit):\\n\")\n",
        "while True:\n",
        "    try:\n",
        "        snippet = input(\"> \").strip()\n",
        "        if not snippet:\n",
        "            break\n",
        "        verdict, conf = classify(snippet)\n",
        "        print(f\"→ {verdict}  (confidence {conf:.1%})\\n\")\n",
        "    except (EOFError, KeyboardInterrupt):\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84IzrpSt1ZmL",
        "outputId": "20f7f88f-9aee-4823-ac15-8e737b5af05d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at openai-community/roberta-base-openai-detector were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Paste text (empty line = quit):\n",
            "\n",
            "> I am a physicist transitioning into the fields of AI/ML and Data Science. I earned my Master's degree at École Polytechnique, France, one of the top 50 universities in the world. Then I worked on a PhD project in quantum optics at the Technical University of Munich, Germany, which ranks among the top 30 universities globally. During that time, I gained extensive experience in experimental work, as well as data analysis of measured experimental data.\n",
            "→ HUMAN  (confidence 81.1%)\n",
            "\n",
            "> While I may not be the ideal candidate due to my recent entry into the field, I  am eager to work hard and continuously learn to deepen my knowledge and  gain more experience\n",
            "→ HUMAN  (confidence 93.9%)\n",
            "\n",
            "> However, the joke creates a humorous image by taking the phrase literally. It suggests that Donald Trump, a figure famously associated with real estate and construction, has misinterpreted the saying. Instead of understanding that the drinks are free, the joke paints a picture of him preparing to physically climb onto the roof of the building.\n",
            "→ HUMAN  (confidence 70.2%)\n",
            "\n",
            "> The moment she stepped outside, the air, cool and heavy with the clean scent of wet asphalt, enveloped her. The first drops were a shock on her warm skin, a series of cold pinpricks on her forehead and the back of her neck. She flinched, a lifetime of conditioning telling her to seek shelter. But she kept walking.\n",
            "→ AI  (confidence 53.2%)\n",
            "\n",
            "> She passed others huddled under awnings or dashing with newspapers over their heads, their faces tight with annoyance. But out here, in the open, it felt different. The rain was not an inconvenience; it was the only thing that was real. Each drop that landed on her felt like it was washing something away—not the dirt from the city, but the frantic buzzing from her mind.\n",
            "→ HUMAN  (confidence 98.2%)\n",
            "\n",
            "> \n"
          ]
        }
      ]
    }
  ]
}